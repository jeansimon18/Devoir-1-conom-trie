{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b6356d1",
   "metadata": {},
   "source": [
    "#  Problème 2: Mesure du Risque\n",
    "\n",
    "**Collecte de données CRSP (2012-2023)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FONCTIONS POUR TÉLÉCHARGER LES DONNÉES CRSP\n",
    "\n",
    "\n",
    "import wrds\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Connexion WRDS réutilisable\n",
    "_db_connection = None\n",
    "\n",
    "def get_wrds_connection(username=None):\n",
    "    \"\"\"Obtient une connexion WRDS réutilisable\"\"\"\n",
    "    global _db_connection\n",
    "    \n",
    "    if _db_connection is None:\n",
    "        if username:\n",
    "            _db_connection = wrds.Connection(wrds_username=username)\n",
    "        else:\n",
    "            _db_connection = wrds.Connection()\n",
    "    \n",
    "    return _db_connection\n",
    "\n",
    "def fetch_crsp(permnos, start='2012-01-03', end='2023-01-03', out_path='crsp_data.csv'):\n",
    "    \"\"\"\n",
    "    Télécharge les données CRSP pour une liste de PERMNOs\n",
    "    \n",
    "    PARAMÈTRES:\n",
    "    -----------\n",
    "    permnos : list - Liste des PERMNOs à télécharger\n",
    "    start : str - Date de début (défaut: '2012-01-03')\n",
    "    end : str - Date de fin (défaut: '2023-01-03')\n",
    "    out_path : str - Fichier de sauvegarde (défaut: 'crsp_data.csv')\n",
    "    \n",
    "    RETOURNE:\n",
    "    ---------\n",
    "    pandas.DataFrame - Données CRSP avec colonnes: date, permno, prc, ret, vol\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        db = get_wrds_connection()\n",
    "        \n",
    "        sql = f\"\"\"\n",
    "        SELECT date, permno, prc, ret, vol\n",
    "        FROM crsp.dsf\n",
    "        WHERE permno IN ({','.join(map(str, permnos))})\n",
    "          AND date BETWEEN '{start}' AND '{end}'\n",
    "        ORDER BY permno, date\n",
    "        \"\"\"\n",
    "        \n",
    "        df = db.raw_sql(sql, date_cols=['date'])\n",
    "        df.to_csv(out_path, index=False)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur: {e}\")\n",
    "        raise\n",
    "\n",
    "def close_connection():\n",
    "    \"\"\"Ferme la connexion WRDS\"\"\"\n",
    "    global _db_connection\n",
    "    if _db_connection:\n",
    "        _db_connection.close()\n",
    "        _db_connection = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "648bee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Liste complète des 10 titres requis\n",
    "permnos_confirmes = [\n",
    "    # INDICE DE MARCHÉ\n",
    "    84398,              # SPY - SPDR S&P 500 ETF Trust\n",
    "    \n",
    "    # SECTEUR FINANCIER\n",
    "    52476,              # EFX - Equifax Inc. \n",
    "    47896,              # JPM - JPMorgan Chase & Co.\n",
    "    90162,              # GNW - Genworth Financial Inc.\n",
    "    \n",
    "    # SECTEUR TECHNOLOGIQUE\n",
    "    75828,              # EA - Electronic Arts Inc.\n",
    "    79094,              # JBL - Jabil Inc.\n",
    "    90319,              # GOOGL - Alphabet Inc. (Class A)\n",
    "    \n",
    "    # SECTEUR ÉNERGÉTIQUE\n",
    "    75825,              # EOG - EOG Resources Inc.\n",
    "    93380,              # JKS - JinkoSolar Holding Co.\n",
    "    92619,              # GTE - Gran Tierra Energy Inc.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27898ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des donnees existantes...\n",
      "Donnees: 27,690 observations pour 10 titres\n",
      "\n",
      "Observations par titre:\n",
      "  JPM (PERMNO 47896): 2,769 observations\n",
      "  EFX (PERMNO 52476): 2,769 observations\n",
      "  EOG (PERMNO 75825): 2,769 observations\n",
      "  EA (PERMNO 75828): 2,769 observations\n",
      "  JBL (PERMNO 79094): 2,769 observations\n",
      "  SPY (PERMNO 84398): 2,769 observations\n",
      "  GNW (PERMNO 90162): 2,769 observations\n",
      "  GOOGL (PERMNO 90319): 2,769 observations\n",
      "  GTE (PERMNO 92619): 2,769 observations\n",
      "  JKS (PERMNO 93380): 2,769 observations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Verifier si les donnees existent deja\n",
    "if os.path.exists('donnees_probleme2.csv'):\n",
    "    print(\"Chargement des donnees existantes...\")\n",
    "    df = pd.read_csv('donnees_probleme2.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "else:\n",
    "    print(\"Telechargement des donnees CRSP...\")\n",
    "    df = fetch_crsp(permnos_confirmes, out_path='donnees_probleme2.csv')\n",
    "    \n",
    "    # Mapping PERMNO -> Ticker et ajout de la colonne\n",
    "    ticker_map = {\n",
    "        84398: 'SPY', 52476: 'EFX', 47896: 'JPM', 90162: 'GNW',\n",
    "        75828: 'EA', 79094: 'JBL', 90319: 'GOOGL',\n",
    "        75825: 'EOG', 93380: 'JKS', 92619: 'GTE'\n",
    "    }\n",
    "    \n",
    "    df['ticker'] = df['permno'].map(ticker_map)\n",
    "    df = df[['date', 'permno', 'ticker', 'prc', 'ret', 'vol']]\n",
    "    df.to_csv('donnees_probleme2.csv', index=False)\n",
    "\n",
    "# Creation des fichiers individuels si necessaire\n",
    "os.makedirs('donnees_individuelles', exist_ok=True)\n",
    "\n",
    "ticker_map = {\n",
    "    84398: 'SPY', 52476: 'EFX', 47896: 'JPM', 90162: 'GNW',\n",
    "    75828: 'EA', 79094: 'JBL', 90319: 'GOOGL',\n",
    "    75825: 'EOG', 93380: 'JKS', 92619: 'GTE'\n",
    "}\n",
    "\n",
    "for permno in permnos_confirmes:\n",
    "    ticker = ticker_map[permno]\n",
    "    fichier = f'donnees_individuelles/{ticker}_{permno}.csv'\n",
    "    if not os.path.exists(fichier):\n",
    "        data_titre = df[df['permno'] == permno]\n",
    "        data_titre.to_csv(fichier, index=False)\n",
    "\n",
    "print(f\"Donnees: {len(df):,} observations pour {df['permno'].nunique()} titres\")\n",
    "print(\"\\nObservations par titre:\")\n",
    "obs_par_titre = df.groupby(['permno', 'ticker']).size().reset_index(name='observations')\n",
    "for _, row in obs_par_titre.iterrows():\n",
    "    print(f\"  {row['ticker']} (PERMNO {row['permno']}): {row['observations']:,} observations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
