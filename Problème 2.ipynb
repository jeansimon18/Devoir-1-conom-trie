{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b6356d1",
   "metadata": {},
   "source": [
    "#  Problème 2: Mesure du Risque\n",
    "\n",
    "**Collecte de données CRSP (2012-2023)**\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "id": "f2bd3f78",
   "metadata": {},
=======
   "execution_count": null,
   "id": "70b5b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FONCTIONS POUR TÉLÉCHARGER LES DONNÉES CRSP\n",
    "\n",
    "\n",
    "import wrds\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Connexion WRDS réutilisable\n",
    "_db_connection = None\n",
    "\n",
    "def get_wrds_connection(username=None):\n",
    "    \"\"\"Obtient une connexion WRDS réutilisable\"\"\"\n",
    "    global _db_connection\n",
    "    \n",
    "    if _db_connection is None:\n",
    "        if username:\n",
    "            _db_connection = wrds.Connection(wrds_username=username)\n",
    "        else:\n",
    "            _db_connection = wrds.Connection()\n",
    "    \n",
    "    return _db_connection\n",
    "\n",
    "def fetch_crsp(permnos, start='2012-01-03', end='2023-01-03', out_path='crsp_data.csv'):\n",
    "    \"\"\"\n",
    "    Télécharge les données CRSP pour une liste de PERMNOs\n",
    "    \n",
    "    PARAMÈTRES:\n",
    "    -----------\n",
    "    permnos : list - Liste des PERMNOs à télécharger\n",
    "    start : str - Date de début (défaut: '2012-01-03')\n",
    "    end : str - Date de fin (défaut: '2023-01-03')\n",
    "    out_path : str - Fichier de sauvegarde (défaut: 'crsp_data.csv')\n",
    "    \n",
    "    RETOURNE:\n",
    "    ---------\n",
    "    pandas.DataFrame - Données CRSP avec colonnes: date, permno, prc, ret, vol\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        db = get_wrds_connection()\n",
    "        \n",
    "        sql = f\"\"\"\n",
    "        SELECT date, permno, prc, ret, vol\n",
    "        FROM crsp.dsf\n",
    "        WHERE permno IN ({','.join(map(str, permnos))})\n",
    "          AND date BETWEEN '{start}' AND '{end}'\n",
    "        ORDER BY permno, date\n",
    "        \"\"\"\n",
    "        \n",
    "        df = db.raw_sql(sql, date_cols=['date'])\n",
    "        df.to_csv(out_path, index=False)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur: {e}\")\n",
    "        raise\n",
    "\n",
    "def close_connection():\n",
    "    \"\"\"Ferme la connexion WRDS\"\"\"\n",
    "    global _db_connection\n",
    "    if _db_connection:\n",
    "        _db_connection.close()\n",
    "        _db_connection = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "648bee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Liste complète des 10 titres requis\n",
    "permnos_confirmes = [\n",
    "    # INDICE DE MARCHÉ\n",
    "    84398,              # SPY - SPDR S&P 500 ETF Trust\n",
    "    \n",
    "    # SECTEUR FINANCIER\n",
    "    52476,              # EFX - Equifax Inc. \n",
    "    47896,              # JPM - JPMorgan Chase & Co.\n",
    "    90162,              # GNW - Genworth Financial Inc.\n",
    "    \n",
    "    # SECTEUR TECHNOLOGIQUE\n",
    "    75828,              # EA - Electronic Arts Inc.\n",
    "    79094,              # JBL - Jabil Inc.\n",
    "    90319,              # GOOGL - Alphabet Inc. (Class A)\n",
    "    \n",
    "    # SECTEUR ÉNERGÉTIQUE\n",
    "    75825,              # EOG - EOG Resources Inc.\n",
    "    93380,              # JKS - JinkoSolar Holding Co.\n",
    "    92619,              # GTE - Gran Tierra Energy Inc.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27898ecb",
   "metadata": {},
>>>>>>> c8202b23de80023031f5f915581a6ddff9d9884b
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "WRDS recommends setting up a .pgpass file.\n",
      "pgpass file created at C:\\Users\\grego\\AppData\\Roaming\\postgresql\\pgpass.conf\n",
      "Created .pgpass file successfully.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "pgpass file created at C:\\Users\\grego\\AppData\\Roaming\\postgresql\\pgpass.conf\n",
      "Created .pgpass file successfully.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n",
      "pgpass file created at C:\\Users\\grego\\AppData\\Roaming\\postgresql\\pgpass.conf\n",
      "pgpass created at: None\n",
      "Done\n",
      "pgpass file created at C:\\Users\\grego\\AppData\\Roaming\\postgresql\\pgpass.conf\n",
      "pgpass created at: None\n"
=======
      "Chargement des donnees existantes...\n",
      "Donnees: 27,690 observations pour 10 titres\n",
      "\n",
      "Observations par titre:\n",
      "  JPM (PERMNO 47896): 2,769 observations\n",
      "  EFX (PERMNO 52476): 2,769 observations\n",
      "  EOG (PERMNO 75825): 2,769 observations\n",
      "  EA (PERMNO 75828): 2,769 observations\n",
      "  JBL (PERMNO 79094): 2,769 observations\n",
      "  SPY (PERMNO 84398): 2,769 observations\n",
      "  GNW (PERMNO 90162): 2,769 observations\n",
      "  GOOGL (PERMNO 90319): 2,769 observations\n",
      "  GTE (PERMNO 92619): 2,769 observations\n",
      "  JKS (PERMNO 93380): 2,769 observations\n"
>>>>>>> c8202b23de80023031f5f915581a6ddff9d9884b
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Create pgpass with WRDS helper (one-time)\n",
    "import wrds\n",
    "try:\n",
    "    # If you’re prompted this time, enter your WRDS username/password once.\n",
    "    # The helper will write the pgpass file to the correct path for your OS.\n",
    "    db = wrds.Connection()\n",
    "    path = db.create_pgpass_file()  # returns the path it wrote to\n",
    "    print(\"pgpass created at:\", path)\n",
    "    db.close()\n",
    "except Exception as e:\n",
    "    print(\"Could not create pgpass:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87015d44",
=======
    "import os\n",
    "\n",
    "# Verifier si les donnees existent deja\n",
    "if os.path.exists('donnees_probleme2.csv'):\n",
    "    print(\"Chargement des donnees existantes...\")\n",
    "    df = pd.read_csv('donnees_probleme2.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "else:\n",
    "    print(\"Telechargement des donnees CRSP...\")\n",
    "    df = fetch_crsp(permnos_confirmes, out_path='donnees_probleme2.csv')\n",
    "    \n",
    "    # Mapping PERMNO -> Ticker et ajout de la colonne\n",
    "    ticker_map = {\n",
    "        84398: 'SPY', 52476: 'EFX', 47896: 'JPM', 90162: 'GNW',\n",
    "        75828: 'EA', 79094: 'JBL', 90319: 'GOOGL',\n",
    "        75825: 'EOG', 93380: 'JKS', 92619: 'GTE'\n",
    "    }\n",
    "    \n",
    "    df['ticker'] = df['permno'].map(ticker_map)\n",
    "    df = df[['date', 'permno', 'ticker', 'prc', 'ret', 'vol']]\n",
    "    df.to_csv('donnees_probleme2.csv', index=False)\n",
    "\n",
    "# Creation des fichiers individuels si necessaire\n",
    "os.makedirs('donnees_individuelles', exist_ok=True)\n",
    "\n",
    "ticker_map = {\n",
    "    84398: 'SPY', 52476: 'EFX', 47896: 'JPM', 90162: 'GNW',\n",
    "    75828: 'EA', 79094: 'JBL', 90319: 'GOOGL',\n",
    "    75825: 'EOG', 93380: 'JKS', 92619: 'GTE'\n",
    "}\n",
    "\n",
    "for permno in permnos_confirmes:\n",
    "    ticker = ticker_map[permno]\n",
    "    fichier = f'donnees_individuelles/{ticker}_{permno}.csv'\n",
    "    if not os.path.exists(fichier):\n",
    "        data_titre = df[df['permno'] == permno]\n",
    "        data_titre.to_csv(fichier, index=False)\n",
    "\n",
    "print(f\"Donnees: {len(df):,} observations pour {df['permno'].nunique()} titres\")\n",
    "print(\"\\nObservations par titre:\")\n",
    "obs_par_titre = df.groupby(['permno', 'ticker']).size().reset_index(name='observations')\n",
    "for _, row in obs_par_titre.iterrows():\n",
    "    print(f\"  {row['ticker']} (PERMNO {row['permno']}): {row['observations']:,} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f24c7",
>>>>>>> c8202b23de80023031f5f915581a6ddff9d9884b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRDS recommends setting up a .pgpass file.\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import wrds\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to WRDS\n",
    "db = wrds.Connection()\n",
    "\n",
    "# Define your list of PERMNOs (replace with your actual list)\n",
    "permnos = [14322, 14020, 84788, 90319]  \n",
    "\n",
    "# Download daily price data from CRSP\n",
    "crsp_data = db.get_table(\n",
    "    library='crsp',\n",
    "    table='dsf',\n",
    "    columns=['date', 'permno', 'prc', 'ret', 'vol'],\n",
    "    obs=None,\n",
    "    where=f\"permno in ({','.join(map(str, permnos))}) and date between '2012-01-03' and '2023-01-03'\"\n",
    ")\n",
    "\n",
    "# Convert to DataFrame if not already\n",
    "df = pd.DataFrame(crsp_data)\n",
    "\n",
    "# Close the connection\n",
    "db.close()\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('crsp_daily_data.csv', index=False)"
=======
    "## Partie (a): Calcul des rendements et statistiques descriptives\n",
    "\n",
    "Pour chaque titre, nous allons :\n",
    "1. Calculer les rendements quotidiens\n",
    "2. Fournir des statistiques descriptives complètes\n",
    "3. Présenter des graphiques de séries chronologiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fec4735",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Configuration des graphiques\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Configuration des graphiques\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except:\n",
    "    # Fallback pour les versions plus récentes de seaborn\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# 1. CALCUL DES RENDEMENTS\n",
    "print(\"=== CALCUL DES RENDEMENTS ===\")\n",
    "\n",
    "# Les rendements sont déjà dans les données CRSP (colonne 'ret')\n",
    "# Mais nous allons aussi calculer les rendements à partir des prix pour vérification\n",
    "\n",
    "# Nettoyer les données (supprimer les valeurs manquantes)\n",
    "df_clean = df.dropna(subset=['ret', 'prc']).copy()\n",
    "\n",
    "# Calculer les rendements à partir des prix (pour vérification)\n",
    "df_clean = df_clean.sort_values(['permno', 'date'])\n",
    "df_clean['ret_calculated'] = df_clean.groupby('permno')['prc'].pct_change()\n",
    "\n",
    "print(f\"Données nettoyées: {len(df_clean):,} observations\")\n",
    "print(f\"Période: {df_clean['date'].min().date()} à {df_clean['date'].max().date()}\")\n",
    "\n",
    "# Vérifier la cohérence entre ret CRSP et ret calculé\n",
    "correlation_check = df_clean.groupby('ticker').apply(\n",
    "    lambda x: x['ret'].corr(x['ret_calculated'], method='pearson')\n",
    ").round(4)\n",
    "\n",
    "print(\"\\nCorrélation entre rendements CRSP et calculés:\")\n",
    "for ticker, corr in correlation_check.items():\n",
    "    print(f\"  {ticker}: {corr}\")\n",
    "\n",
    "# Utiliser les rendements CRSP (plus fiables)\n",
    "print(\"\\n>>> Utilisation des rendements CRSP pour l'analyse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed1a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. STATISTIQUES DESCRIPTIVES COMPLÈTES\n",
    "print(\"\\n=== STATISTIQUES DESCRIPTIVES ===\")\n",
    "\n",
    "# Fonction pour calculer des statistiques complètes\n",
    "def statistiques_descriptives(series, nom):\n",
    "    \"\"\"Calcule des statistiques descriptives complètes pour une série de rendements\"\"\"\n",
    "    stats_dict = {\n",
    "        'Moyenne (%)': series.mean() * 100,\n",
    "        'Médiane (%)': series.median() * 100,\n",
    "        'Écart-type (%)': series.std() * 100,\n",
    "        'Volatilité annualisée (%)': series.std() * np.sqrt(252) * 100,\n",
    "        'Asymétrie (Skewness)': stats.skew(series),\n",
    "        'Aplatissement (Kurtosis)': stats.kurtosis(series),\n",
    "        'Minimum (%)': series.min() * 100,\n",
    "        'Maximum (%)': series.max() * 100,\n",
    "        'Q1 (%)': series.quantile(0.25) * 100,\n",
    "        'Q3 (%)': series.quantile(0.75) * 100,\n",
    "        'Observations': len(series)\n",
    "    }\n",
    "    return stats_dict\n",
    "\n",
    "# Créer un DataFrame pour les statistiques\n",
    "stats_results = []\n",
    "\n",
    "# Organisation par secteur pour l'affichage\n",
    "secteurs = {\n",
    "    'Indice de marché': ['SPY'],\n",
    "    'Secteur financier': ['EFX', 'JPM', 'GNW'],\n",
    "    'Secteur technologique': ['EA', 'JBL', 'GOOGL'],\n",
    "    'Secteur énergétique': ['EOG', 'JKS', 'GTE']\n",
    "}\n",
    "\n",
    "# Calculer les statistiques pour chaque titre\n",
    "for secteur, tickers in secteurs.items():\n",
    "    print(f\"\\n{secteur.upper()}:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        data_ticker = df_clean[df_clean['ticker'] == ticker]['ret'].dropna()\n",
    "        if len(data_ticker) > 0:\n",
    "            stats_ticker = statistiques_descriptives(data_ticker, ticker)\n",
    "            stats_ticker['Secteur'] = secteur\n",
    "            stats_ticker['Ticker'] = ticker\n",
    "            stats_results.append(stats_ticker)\n",
    "            \n",
    "            # Affichage formaté\n",
    "            print(f\"{ticker} ({len(data_ticker)} obs):\")\n",
    "            print(f\"  Rendement moyen: {stats_ticker['Moyenne (%)']:.4f}%\")\n",
    "            print(f\"  Volatilité annuelle: {stats_ticker['Volatilité annualisée (%)']:.2f}%\")\n",
    "            print(f\"  Asymétrie: {stats_ticker['Asymétrie (Skewness)']:.3f}\")\n",
    "            print(f\"  Aplatissement: {stats_ticker['Aplatissement (Kurtosis)']:.3f}\")\n",
    "            print(f\"  Min/Max: {stats_ticker['Minimum (%)']:.2f}% / {stats_ticker['Maximum (%)']:.2f}%\")\n",
    "            print()\n",
    "\n",
    "# Créer un DataFrame des résultats pour export\n",
    "stats_df = pd.DataFrame(stats_results)\n",
    "print(\"=== TABLEAU RÉCAPITULATIF ===\")\n",
    "print(stats_df[['Ticker', 'Secteur', 'Moyenne (%)', 'Volatilité annualisée (%)', \n",
    "                'Asymétrie (Skewness)', 'Aplatissement (Kurtosis)']].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. GRAPHIQUES DE SÉRIES CHRONOLOGIQUES\n",
    "print(\"\\n=== GRAPHIQUES DE SÉRIES CHRONOLOGIQUES ===\")\n",
    "\n",
    "# A. Prix ajustés dans le temps\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Évolution des Prix Ajustés (2012-2023)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Graphique 1: Indice de marché\n",
    "ax1 = axes[0, 0]\n",
    "spy_data = df_clean[df_clean['ticker'] == 'SPY']\n",
    "ax1.plot(spy_data['date'], spy_data['prc'], color='blue', linewidth=1.5)\n",
    "ax1.set_title('SPY - Indice S&P 500', fontweight='bold')\n",
    "ax1.set_ylabel('Prix ($)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 2: Secteur financier\n",
    "ax2 = axes[0, 1]\n",
    "for ticker in ['EFX', 'JPM', 'GNW']:\n",
    "    data = df_clean[df_clean['ticker'] == ticker]\n",
    "    ax2.plot(data['date'], data['prc'], label=ticker, linewidth=1.5)\n",
    "ax2.set_title('Secteur Financier', fontweight='bold')\n",
    "ax2.set_ylabel('Prix ($)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 3: Secteur technologique\n",
    "ax3 = axes[1, 0]\n",
    "for ticker in ['EA', 'JBL', 'GOOGL']:\n",
    "    data = df_clean[df_clean['ticker'] == ticker]\n",
    "    ax3.plot(data['date'], data['prc'], label=ticker, linewidth=1.5)\n",
    "ax3.set_title('Secteur Technologique', fontweight='bold')\n",
    "ax3.set_ylabel('Prix ($)')\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 4: Secteur énergétique\n",
    "ax4 = axes[1, 1]\n",
    "for ticker in ['EOG', 'JKS', 'GTE']:\n",
    "    data = df_clean[df_clean['ticker'] == ticker]\n",
    "    ax4.plot(data['date'], data['prc'], label=ticker, linewidth=1.5)\n",
    "ax4.set_title('Secteur Énergétique', fontweight='bold')\n",
    "ax4.set_ylabel('Prix ($)')\n",
    "ax4.set_xlabel('Date')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Graphique des prix ajustés affiché.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Rendements quotidiens dans le temps\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Rendements Quotidiens (2012-2023)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Graphique 1: Indice de marché\n",
    "ax1 = axes[0, 0]\n",
    "spy_data = df_clean[df_clean['ticker'] == 'SPY']\n",
    "ax1.plot(spy_data['date'], spy_data['ret'] * 100, color='blue', linewidth=0.8, alpha=0.7)\n",
    "ax1.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "ax1.set_title('SPY - Rendements Quotidiens', fontweight='bold')\n",
    "ax1.set_ylabel('Rendement (%)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 2: Secteur financier\n",
    "ax2 = axes[0, 1]\n",
    "for ticker in ['EFX', 'JPM', 'GNW']:\n",
    "    data = df_clean[df_clean['ticker'] == ticker]\n",
    "    ax2.plot(data['date'], data['ret'] * 100, label=ticker, linewidth=0.8, alpha=0.7)\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "ax2.set_title('Secteur Financier - Rendements', fontweight='bold')\n",
    "ax2.set_ylabel('Rendement (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 3: Secteur technologique\n",
    "ax3 = axes[1, 0]\n",
    "for ticker in ['EA', 'JBL', 'GOOGL']:\n",
    "    data = df_clean[df_clean['ticker'] == ticker]\n",
    "    ax3.plot(data['date'], data['ret'] * 100, label=ticker, linewidth=0.8, alpha=0.7)\n",
    "ax3.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "ax3.set_title('Secteur Technologique - Rendements', fontweight='bold')\n",
    "ax3.set_ylabel('Rendement (%)')\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 4: Secteur énergétique\n",
    "ax4 = axes[1, 1]\n",
    "for ticker in ['EOG', 'JKS', 'GTE']:\n",
    "    data = df_clean[df_clean['ticker'] == ticker]\n",
    "    ax4.plot(data['date'], data['ret'] * 100, label=ticker, linewidth=0.8, alpha=0.7)\n",
    "ax4.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "ax4.set_title('Secteur Énergétique - Rendements', fontweight='bold')\n",
    "ax4.set_ylabel('Rendement (%)')\n",
    "ax4.set_xlabel('Date')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Graphique des rendements quotidiens affiché.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Histogrammes des distributions de rendements\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "fig.suptitle('Distribution des Rendements Quotidiens par Titre', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Liste de tous les tickers par ordre\n",
    "all_tickers = ['SPY', 'EFX', 'JPM', 'GNW', 'EA', 'JBL', 'GOOGL', 'EOG', 'JKS', 'GTE']\n",
    "secteur_colors = {\n",
    "    'SPY': 'blue', 'EFX': 'red', 'JPM': 'red', 'GNW': 'red',\n",
    "    'EA': 'green', 'JBL': 'green', 'GOOGL': 'green',\n",
    "    'EOG': 'orange', 'JKS': 'orange', 'GTE': 'orange'\n",
    "}\n",
    "\n",
    "for i, ticker in enumerate(all_tickers):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    \n",
    "    # Si on dépasse les axes disponibles, passer au suivant\n",
    "    if row >= 3:\n",
    "        break\n",
    "        \n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Données du ticker\n",
    "    data = df_clean[df_clean['ticker'] == ticker]['ret'].dropna() * 100\n",
    "    \n",
    "    if len(data) > 0:\n",
    "        # Histogramme\n",
    "        ax.hist(data, bins=50, alpha=0.7, color=secteur_colors[ticker], density=True)\n",
    "        \n",
    "        # Courbe normale de référence\n",
    "        mu, sigma = data.mean(), data.std()\n",
    "        x = np.linspace(data.min(), data.max(), 100)\n",
    "        normal_curve = stats.norm.pdf(x, mu, sigma)\n",
    "        ax.plot(x, normal_curve, 'k--', linewidth=2, label='Normale')\n",
    "        \n",
    "        # Statistiques sur le graphique\n",
    "        ax.axvline(mu, color='red', linestyle='-', alpha=0.8, label=f'Moyenne: {mu:.2f}%')\n",
    "        ax.axvline(mu + sigma, color='red', linestyle=':', alpha=0.6)\n",
    "        ax.axvline(mu - sigma, color='red', linestyle=':', alpha=0.6)\n",
    "        \n",
    "        ax.set_title(f'{ticker}', fontweight='bold')\n",
    "        ax.set_xlabel('Rendement (%)')\n",
    "        ax.set_ylabel('Densité')\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Supprimer les axes vides\n",
    "for i in range(len(all_tickers), 12):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    if row < 3:\n",
    "        axes[row, col].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Histogrammes des distributions de rendements affichés.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee282a5",
   "metadata": {},
   "source": [
    "### Interprétation des Résultats - Partie (a)\n",
    "\n",
    "#### **Statistiques Descriptives - Observations Clés:**\n",
    "\n",
    "1. **Rendements moyens**: Tous les titres montrent des rendements moyens positifs sur la période 2012-2023, reflétant la tendance haussière générale des marchés.\n",
    "\n",
    "2. **Volatilité par secteur**:\n",
    "   - **Secteur énergétique**: Généralement la plus haute volatilité (particulièrement JKS et GTE)\n",
    "   - **Secteur technologique**: Volatilité modérée à élevée \n",
    "   - **Secteur financier**: Volatilité modérée\n",
    "   - **Indice SPY**: Plus faible volatilité (effet de diversification)\n",
    "\n",
    "3. **Asymétrie (Skewness)**: La plupart des séries montrent une asymétrie négative, indiquant des queues de distribution étendues vers les rendements négatifs (caractéristique typique des actifs financiers).\n",
    "\n",
    "4. **Aplatissement (Kurtosis)**: Valeurs élevées pour tous les titres, signalant des distributions leptokurtiques avec des queues épaisses (plus de rendements extrêmes que prédit par la distribution normale).\n",
    "\n",
    "#### **Analyse des Graphiques:**\n",
    "\n",
    "- **Évolution des prix**: Tendance générale haussière avec des corrections notables (2015-2016, 2018, 2020)\n",
    "- **Rendements**: Volatilité en clusters visible, particulièrement durant les crises (2020, 2022)\n",
    "- **Distributions**: Écarts significatifs par rapport à la normalité, justifiant l'utilisation de méthodes non-paramétriques pour la mesure du risque"
>>>>>>> c8202b23de80023031f5f915581a6ddff9d9884b
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
